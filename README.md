# Awesome LLM Research

> Curation of resources for LLM research.

[![Awesome](https://awesome.re/badge.svg)](https://github.com/tongyx361/Awesome-LLM-Research)
[![License: Apache](https://img.shields.io/badge/License-Apache-green.svg)](https://opensource.org/licenses/Apache)

For the most updated list, please refer to the [Notion page](https://tongyx361.notion.site/Awesome-LLM-Research-f1b35e05436f4e69b4293ae81b425430).

:bell: If you have any suggestions, please don't hesitate to let us know. You can

- directly [E-mail Yuxuan Tong](tongyuxuan361@gmail.com),
- comment on the [Notion page](https://tongyx361.notion.site/Awesome-LLM-Research-f1b35e05436f4e69b4293ae81b425430),
- or post an issue on this repo.

| Link                                                                                                                           | Abstract                                                                                         | Description                                                                                                                                                       |
| ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [国立台湾大学: 李宏毅机器学习 - CS自学指南](https://csdiy.wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LHY/)                                       | **Basic theory and fundamental works** of Deep Learning                                          | Lectures from different years have different focuses, e.g. 2023 focuses on LLM                                                                                    |
| [Introduction - Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1)                                   | Basic NLP **practice** (based on HuggingFace ecosystem)                                          | HuggingFace is so accessible that its success is a given (but this also comes with some hidden price for developers).                                             |
| [Yao Fu’s Blog](https://yaofu.notion.site/Yao-Fu-s-Blog-b536c3d6912149a395931f1e871370db)                                      | Foudamental research topics **walkthrough**                                                      | Such as emergent abilities, reasoning, long-context modeling.                                                                                                     |
| [Transformer Math 101 \| EleutherAI Blog](https://blog.eleuther.ai/transformer-math/)                                          | Transformer-related math estimation - Basic                                                      | Basic arithmetic about Transformer-based models.                                                                                                                  |
| [分析transformer模型的参数量、计算量、中间激活、KV cache - 知乎](https://zhuanlan.zhihu.com/p/624740065)                                           | Transformer-related math estimation - Mediate                                                    | Detailed analysis of calculations in Transformer-based model.                                                                                                     |
| [紫气东来 - 知乎](https://www.zhihu.com/people/zi-qi-dong-lai-1/posts)                                                               | **Specific** engineering details                                                                 | Such as inference and training frameworks.                                                                                                                        |
| Wechat official account *吃果冻不吐果冻皮*                                                                                             | Engineering detail **summaries**                                                                 | Summarizing AI engineering techniques, such as inference, parallel computing, etc.                                                                                |
| [游凯超 - 知乎](https://www.zhihu.com/people/youkaichao)                                                                            | **Infrastructure-level** engineering details                                                     | Such as CUDA, NCCL, torch.compile and other side infrastructures like Docker, etc.                                                                                |
| [Alignment Guidebook - Notion](https://efficient-unicorn-451.notion.site/Alignment-Guidebook-e5c64df77c0a4b528b7951e87337fa78) | Introduction to LLM **Alignment (SFT + RL)**                                                     |                                                                                                                                                                   |
| [Spinning Up in Deep RL! — Spinning Up documentation](https://spinningup.openai.com/en/latest/)                                | Basic **Deep RL**                                                                                |                                                                                                                                                                   |
| [科学空间\|Scientific Spaces](https://kexue.fm/)                                                                                   | Blogs combining **graceful theories** and solid experiments                                      | Blogs by 苏剑林, the author of RoPE (de facto standard of positional encoding now), versed in math and ML theory while not unfamiliar with experiments and practice. |
| [Research](https://openai.com/research/overview)                                                                               | **OpenAI** research blogs                                                                        | We keep re-discovering what OpenAI discovered five years ago.                                                                                                     |
| [Research \\ Anthropic](https://www.anthropic.com/research)                                                                    | **Anthropic** research blogs                                                                     |                                                                                                                                                                   |
| E.g. [\[2312.11805\] Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/abs/2312.11805)                   | LLM **technical reports**                                                                        | Such technical reports, while usually not very detailed, often do reveal some important details of SotA LLMs.                                                     |
| [Hazy Research](https://hazyresearch.stanford.edu/blog)                                                                        | Blogs of **pioneer visions**                                                                     | Blogs from HazyResearch led by Chris. Re @ Stanford (one of the best NLP&AI research groups around the world)                                                     |
| [Cool Papers - Immersive Paper Discovery](https://papers.cool/)                                                                | **Daily arXiv** paper & Kimi interaction                                                         |                                                                                                                                                                   |
| [Daily Papers - Hugging Face](https://huggingface.co/papers)                                                                   | Paper selection by **AK (pre-senior researcher at OpenAI & Tesla)**                              | The most famous paper selection on Twitter.                                                                                                                       |
| Wechat official account *SparksofAGI*                                                                                          | Individual paper selection, some of which **common popular paper collections might not notice**. | Selected by Jianbo Dai (戴建波) (senior researcher at Huawei)                                                                                                        |
| Wechat official account *AINLP*                                                                                                | **Curations** of other AI WeChat official accounts                                               |                                                                                                                                                                   |
| ”Big Four” in Chinese AI media：*机器之心*、*新智元*、*量子位*、*夕小瑶科技说*                                                                     | **Popular** paper selection                                                                      |                                                                                                                                                                   |
| Wechat official account: *arXiv 每日学术速递*                                                                                        | arXiv paper from **broader domains**                                                             |                                                                                                                                                                   |
| Wechat official account: *AI 前线*                                                                                               | Various AI news **(not limited to research)**                                                    |                                                                                                                                                                   |
